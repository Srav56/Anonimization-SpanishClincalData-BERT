{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b26f0af25b54c47a63749204a50f22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78363f2c418042eaa55496b80ba80286",
              "IPY_MODEL_3c683be4ed9844ffb4e3705204d54b0f",
              "IPY_MODEL_c067126974df4fa4bcb110f7fe859d94"
            ],
            "layout": "IPY_MODEL_a305bea1cdf642d7941faed977f615e7"
          }
        },
        "78363f2c418042eaa55496b80ba80286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3f2cef5251440fb80b54e0f4385509c",
            "placeholder": "​",
            "style": "IPY_MODEL_e30ac082ad904a62a9f650af6ce79181",
            "value": "Downloading builder script: 100%"
          }
        },
        "3c683be4ed9844ffb4e3705204d54b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066c4d4ae47745c4887d2ec8d72633ce",
            "max": 6338,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea401c1d86324bac90d51b4fc0b4ec85",
            "value": 6338
          }
        },
        "c067126974df4fa4bcb110f7fe859d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d581be105844fe98f0d37878ce3e7c1",
            "placeholder": "​",
            "style": "IPY_MODEL_8a7fee8683034b01bca4145c6a311eee",
            "value": " 6.34k/6.34k [00:00&lt;00:00, 113kB/s]"
          }
        },
        "a305bea1cdf642d7941faed977f615e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f2cef5251440fb80b54e0f4385509c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30ac082ad904a62a9f650af6ce79181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "066c4d4ae47745c4887d2ec8d72633ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea401c1d86324bac90d51b4fc0b4ec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d581be105844fe98f0d37878ce3e7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7fee8683034b01bca4145c6a311eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-sgUbzBXPZK"
      },
      "source": [
        "!pip install -U accelerate\n",
        "!pip install -U transformers seqeval[gpu]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate seqeval[gpu]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJi_NJNhSb-a",
        "outputId": "00c4a310-ac42-4be4-9e40-ea9f2b1445aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEnlUbgm8z3B"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def read_data(file_path):\n",
        "    file_path = Path(file_path)\n",
        "\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    #print(raw_text[:100])\n",
        "    raw_docs = re.split(r'\\n', raw_text)\n",
        "    print(raw_docs[:100])\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            if len(line) < 3:\n",
        "              continue\n",
        "            token, tag, sentence= line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs\n",
        "\n",
        "texts, tags = read_data('output.tsv')"
      ],
      "metadata": {
        "id": "CLbYrB5-ql56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm1krxJtKxpx",
        "tags": []
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_text,val_text, train_tags,  val_tags = train_test_split(texts,tags, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jyqQJGyZJATd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tags = set(tag for doc in tags for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}"
      ],
      "metadata": {
        "id": "WZq3oNgzTsH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = list(unique_tags)"
      ],
      "metadata": {
        "id": "G--cM-RyJ_Q2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')\n",
        "\n",
        "#train_texts = train_data['Token'].tolist()\n",
        "#val_texts = val_data['Token'].tolist()\n",
        "\n",
        "\n",
        "train_encodings = tokenizer(train_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "1m5dttFgJ_MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def encode_tags(tags, encodings):\n",
        "  print(tags[:10])\n",
        "  labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
        "  encoded_labels = []\n",
        "  for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "        # create an empty array of -100\n",
        "    doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "    arr_offset = np.array(doc_offset)\n",
        "\n",
        "    # set labels whose first offset position is 0 and the second is not 0\n",
        "    doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "    encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "  return encoded_labels\n",
        "\n",
        "#train_tags = train_data['Tag'].tolist()\n",
        "#val_tags = val_data['Tag'].tolist()\n",
        "\n",
        "train_labels = encode_tags(train_tags, train_encodings)\n",
        "val_labels = encode_tags(val_tags, val_encodings)"
      ],
      "metadata": {
        "id": "JwSJR7M5ORDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class MEDOCCANDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "train_dataset = MEDOCCANDataset(train_encodings, train_labels)\n",
        "val_dataset = MEDOCCANDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "VmPQe55uffA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForTokenClassification\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased', num_labels=len(unique_tags))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "oZmryA-PgvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Flatten the predictions and labels for sklearn's classification_report\n",
        "    labels_flat = [label for sublist in labels for label in sublist]\n",
        "    preds_flat = [pred for sublist in preds for pred in sublist]\n",
        "\n",
        "    # Generate classification report\n",
        "    classification_rep = classification_report(labels_flat, preds_flat, output_dict=True)\n",
        "\n",
        "    # Calculate overall metrics\n",
        "    overall_metrics = {\n",
        "        \"accuracy\": classification_rep['accuracy'],\n",
        "        \"precision\": classification_rep['macro avg']['precision'],\n",
        "        \"recall\": classification_rep['macro avg']['recall'],\n",
        "        \"f1_score\": classification_rep['macro avg']['f1-score']\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"overall\": overall_metrics\n",
        "    }\n"
      ],
      "metadata": {
        "id": "TL3Igcamv54b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4HTSutCzGtmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3b26f0af25b54c47a63749204a50f22d",
            "78363f2c418042eaa55496b80ba80286",
            "3c683be4ed9844ffb4e3705204d54b0f",
            "c067126974df4fa4bcb110f7fe859d94",
            "a305bea1cdf642d7941faed977f615e7",
            "e3f2cef5251440fb80b54e0f4385509c",
            "e30ac082ad904a62a9f650af6ce79181",
            "066c4d4ae47745c4887d2ec8d72633ce",
            "ea401c1d86324bac90d51b4fc0b4ec85",
            "3d581be105844fe98f0d37878ce3e7c1",
            "8a7fee8683034b01bca4145c6a311eee"
          ]
        },
        "id": "QXaCzcLqGuQm",
        "outputId": "f1cac377-f7e2-424a-daef-34f66ce3e5f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b26f0af25b54c47a63749204a50f22d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from transformers import Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# Defining test dataset\n",
        "test_texts, test_tags = read_data('test.tsv')\n",
        "test_encodings = tokenizer(test_texts, is_split_into_words=True,\n",
        "                          return_offsets_mapping=True, padding=True,\n",
        "                           truncation=True)\n",
        "test_labels = encode_tags(test_tags, test_encodings)\n",
        "test_dataset = MEDOCCANDataset(test_encodings, test_labels)  # Replace with your actual test dataset\n",
        "\n",
        "# Initialize an empty list to store predictions\n",
        "all_test_predictions = []\n",
        "\n",
        "k = 3  # Number of folds\n",
        "kf = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# Initialize your model, tokenizer, datasets, and other components\n",
        "\n",
        "for fold, (train_index, eval_index) in enumerate(kf.split(train_encodings)):\n",
        "    print(f\"Training fold {fold + 1}/{k}\")\n",
        "\n",
        "    # Split data into train and eval for this fold\n",
        "    train_inputs_fold = [train_encodings[i] for i in train_index]\n",
        "    train_labels_fold = [train_labels[i] for i in train_index]\n",
        "    eval_inputs_fold = [val_encodings[i] for i in eval_index]\n",
        "    eval_labels_fold = [val_labels[i] for i in eval_index]\n",
        "\n",
        "    # Instantiate your Trainer and TrainingArguments for this fold\n",
        "    training_args_fold = TrainingArguments(\n",
        "        output_dir=f'./results_fold_{fold}',  # Directory for results\n",
        "        num_train_epochs=3,                  # Total number of training epochs\n",
        "        per_device_train_batch_size=12,       # Batch size per GPU\n",
        "        logging_dir=f'./logs_fold_{fold}',    # Directory for storing logs\n",
        "        save_strategy = \"epoch\",                       # Save model checkpoint every 500 steps\n",
        "        evaluation_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
        "        logging_steps=100,                    # Log metrics every 100 steps\n",
        "        learning_rate=3e-5,                   # Learning rate\n",
        "        gradient_accumulation_steps=1,        # Number of updates steps before backward pass\n",
        "        weight_decay=0.0,                     # Weight decay (if applicable)\n",
        "        adam_beta1=0.9,                       # AdamW beta1\n",
        "        adam_beta2=0.999,                     # AdamW beta2\n",
        "        adam_epsilon=1e-8,                    # AdamW epsilon\n",
        "        max_grad_norm=1.0,                    # Gradient clipping threshold\n",
        "        warmup_steps=500,                     # Number of warmup steps for the scheduler\n",
        "        load_best_model_at_end=True,          # Load the best model when training ends\n",
        "        metric_for_best_model='eval_loss',    # Metric to use to determine the best model\n",
        "        greater_is_better=False               # Indicate if higher metric values are better\n",
        "    )\n",
        "\n",
        "    # Instantiate AdamW optimizer and scheduler for this fold\n",
        "    optimizer_fold = AdamW(model.parameters(), lr=training_args_fold.learning_rate,\n",
        "                           betas=(training_args_fold.adam_beta1, training_args_fold.adam_beta2),\n",
        "                           eps=training_args_fold.adam_epsilon)\n",
        "    num_training_steps_fold = len(train_inputs_fold) // (training_args_fold.per_device_train_batch_size *\n",
        "                                                        training_args_fold.gradient_accumulation_steps) * training_args_fold.num_train_epochs\n",
        "    scheduler_fold = get_linear_schedule_with_warmup(optimizer_fold, num_warmup_steps=training_args_fold.warmup_steps,\n",
        "                                                    num_training_steps=num_training_steps_fold)\n",
        "\n",
        "    # Initialize Trainer for this fold\n",
        "    trainer_fold = Trainer(\n",
        "        model=model,\n",
        "        args=training_args_fold,\n",
        "        optimizers=(optimizer_fold,scheduler_fold),\n",
        "        train_dataset= MEDOCCANDataset(train_encodings, train_labels),\n",
        "        eval_dataset= MEDOCCANDataset(val_encodings, val_labels),\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model for this fold\n",
        "    trainer_fold.train()\n",
        "\n",
        "    # Evaluate the model for this fold\n",
        "    evaluation_result = trainer_fold.evaluate()\n",
        "    print(f\"Evaluation result for fold {fold + 1}/{k}:\")\n",
        "    print(evaluation_result)\n",
        "    test_predictions = trainer_fold.predict(test_dataset)\n",
        "    all_test_predictions.append(test_predictions)\n",
        "    model.save_pretrained(f\"./model/best_model_fold_{fold + 1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "FXBooA0JuvVK",
        "outputId": "97ff1aba-b36b-441c-c8fe-fd4a2253aa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Token\\tTag\\tSentence #', 'Datos\\tO\\tSentence 1', 'del\\tO\\tSentence 2', 'paciente\\tO\\tSentence 2', '.\\tO\\tSentence 2', '\"', '\"\\tO\\tSentence 2', 'Nombre\\tO\\tSentence 2', ':\\tO\\tSentence 3', ' \\tO\\tSentence 3', 'Ignacio\\tB-NOMBRE_SUJETO_ASISTENCIA\\tSentence 3', '.\\tO\\tSentence 3', '\"', '\"\\tO\\tSentence 3', 'Apellidos\\tO\\tSentence 3', ':\\tO\\tSentence 4', 'Rico\\tB-NOMBRE_SUJETO_ASISTENCIA\\tSentence 4', 'Pedroza\\tI-NOMBRE_SUJETO_ASISTENCIA\\tSentence 4', '.\\tO\\tSentence 4', '\"', '\"\\tO\\tSentence 4', 'NHC\\tO\\tSentence 4', ':\\tO\\tSentence 5', '5467980\\tB-ID_SUJETO_ASISTENCIA\\tSentence 5', '.\\tO\\tSentence 5', '\"', '\"\\tO\\tSentence 5', 'Domicilio\\tO\\tSentence 5', ':\\tO\\tSentence 6', 'Av.\\tB-CALLE\\tSentence 6', 'Beniarda\\tI-CALLE\\tSentence 6', ',\\tI-CALLE\\tSentence 6', '13\\tI-CALLE\\tSentence 6', '.\\tO\\tSentence 6', '\"', '\"\\tO\\tSentence 6', 'Localidad/\\tO\\tSentence 6', 'Provincia\\tO\\tSentence 7', ':\\tO\\tSentence 7', 'Valencia\\tB-TERRITORIO\\tSentence 7', '.\\tO\\tSentence 7', '\"', '\"\\tO\\tSentence 7', 'CP\\tO\\tSentence 7', ':\\tO\\tSentence 8', '46271\\tB-TERRITORIO\\tSentence 8', '.\\tO\\tSentence 8', '\"', '\"\\tO\\tSentence 8', 'Datos\\tO\\tSentence 8', 'asistenciales\\tO\\tSentence 9', '.\\tO\\tSentence 9', '\"', '\"\\tO\\tSentence 9', 'Fecha\\tO\\tSentence 9', 'de\\tO\\tSentence 10', 'nacimiento\\tO\\tSentence 10', ':\\tO\\tSentence 10', '11/02/1970\\tB-FECHAS\\tSentence 10', '.\\tO\\tSentence 10', '\"', '\"\\tO\\tSentence 10', 'País\\tO\\tSentence 10', ':\\tO\\tSentence 11', 'España\\tB-PAIS\\tSentence 11', '.\\tO\\tSentence 11', '\"', '\"\\tO\\tSentence 11', 'Edad\\tO\\tSentence 11', ':\\tO\\tSentence 12', '46\\tB-EDAD_SUJETO_ASISTENCIA\\tSentence 12', 'años\\tI-EDAD_SUJETO_ASISTENCIA\\tSentence 12', 'Sexo\\tO\\tSentence 12', ':\\tO\\tSentence 12', 'H.\\tO\\tSentence 12', '\"', '\"\\tO\\tSentence 12', 'Fecha\\tO\\tSentence 12', 'de\\tO\\tSentence 12', 'Ingreso\\tO\\tSentence 12', ':\\tO\\tSentence 12', '28/05/2016\\tB-FECHAS\\tSentence 12', '.\\tO\\tSentence 12', '\"', '\"\\tO\\tSentence 12', 'Médico\\tO\\tSentence 12', ':\\tO\\tSentence 13', ' \\tO\\tSentence 13', 'Ignacio\\tB-NOMBRE_PERSONAL_SANITARIO\\tSentence 13', 'Rubio\\tI-NOMBRE_PERSONAL_SANITARIO\\tSentence 13', 'Tortosa\\tI-NOMBRE_PERSONAL_SANITARIO\\tSentence 13', 'Servicio\\tO\\tSentence 13', ' \\tO\\tSentence 13', 'NºCol\\tO\\tSentence 13', ':\\tO\\tSentence 13', '46\\tB-ID_TITULACION_PERSONAL_SANITARIO\\tSentence 13', '28\\tI-ID_TITULACION_PERSONAL_SANITARIO\\tSentence 13', '52938\\tI-ID_TITULACION_PERSONAL_SANITARIO\\tSentence 13', '.\\tO\\tSentence 13', '\"']\n",
            "[['Tag'], ['O'], ['O'], ['O'], ['O'], [], ['O'], ['O'], ['O'], ['O']]\n",
            "Training fold 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54471' max='54471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54471/54471 1:41:23, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.555300</td>\n",
              "      <td>0.665285</td>\n",
              "      <td>0.235167</td>\n",
              "      <td>0.147630</td>\n",
              "      <td>0.181390</td>\n",
              "      <td>0.888296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.579600</td>\n",
              "      <td>0.665285</td>\n",
              "      <td>0.235167</td>\n",
              "      <td>0.147630</td>\n",
              "      <td>0.181390</td>\n",
              "      <td>0.888296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.576300</td>\n",
              "      <td>0.665285</td>\n",
              "      <td>0.235167</td>\n",
              "      <td>0.147630</td>\n",
              "      <td>0.181390</td>\n",
              "      <td>0.888296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result for fold 1/3:\n",
            "{'eval_loss': 0.6652845144271851, 'eval_precision': 0.23516720604099245, 'eval_recall': 0.14762979683972913, 'eval_f1': 0.1813895437526002, 'eval_accuracy': 0.8882963472676185, 'eval_runtime': 103.9491, 'eval_samples_per_second': 524.026, 'eval_steps_per_second': 65.503, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Tag seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='54471' max='54471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54471/54471 1:41:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.504200</td>\n",
              "      <td>0.609359</td>\n",
              "      <td>0.717272</td>\n",
              "      <td>0.147178</td>\n",
              "      <td>0.244240</td>\n",
              "      <td>0.926391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.511700</td>\n",
              "      <td>0.609359</td>\n",
              "      <td>0.717272</td>\n",
              "      <td>0.147178</td>\n",
              "      <td>0.244240</td>\n",
              "      <td>0.926391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.540500</td>\n",
              "      <td>0.609359</td>\n",
              "      <td>0.717272</td>\n",
              "      <td>0.147178</td>\n",
              "      <td>0.244240</td>\n",
              "      <td>0.926391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation result for fold 2/3:\n",
            "{'eval_loss': 0.6093586683273315, 'eval_precision': 0.7172717271727173, 'eval_recall': 0.1471783295711061, 'eval_f1': 0.24424049447462073, 'eval_accuracy': 0.9263910392415468, 'eval_runtime': 104.1898, 'eval_samples_per_second': 522.815, 'eval_steps_per_second': 65.352, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Tag seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13063' max='54471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13063/54471 22:45 < 1:12:09, 9.56 it/s, Epoch 0.72/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate aggregated predictions on the test set\n",
        "final_test_predictions = np.argmax(np.mean([pred.predictions for pred in all_test_predictions], axis=0), axis=-1)\n",
        "\n",
        "# True labels for the test set\n",
        "true_labels_test = [label for sublist in test_labels for label in sublist]\n",
        "\n",
        "# Calculate metrics for the test set\n",
        "test_classification_report = classification_report(true_labels_test, final_test_predictions)\n",
        "test_confusion_matrix = confusion_matrix(true_labels_test, final_test_predictions)\n",
        "\n",
        "# Print or use the classification report and confusion matrix\n",
        "print(\"Test Classification Report:\")\n",
        "print(test_classification_report)\n",
        "\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(test_confusion_matrix)"
      ],
      "metadata": {
        "id": "lQG5ClHpzcc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup, AutoConfig, AutoModelForTokenClassification\n",
        "\n",
        "\n",
        "# After saving, you can upload your model to the Hugging Face Model Hub using the following command in the terminal\n",
        "!transformers-cli login  # Log in to your Hugging Face account\n",
        "!transformers-cli repo create NER-BERT-MEDOCCAN-KFold  # Create a new repository for your model\n",
        "!transformers-cli push './model/'  # Push your saved model to the Hub\n"
      ],
      "metadata": {
        "id": "nJV8fSsbz6Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "'''"
      ],
      "metadata": {
        "id": "c-RSX2-AhLim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wbskCTQrwy0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}